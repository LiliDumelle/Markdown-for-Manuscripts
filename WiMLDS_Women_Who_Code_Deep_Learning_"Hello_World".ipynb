{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WiMLDS/Women Who Code Deep Learning \"Hello World\"",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/LiliDumelle/Markdown-for-Manuscripts/blob/master/WiMLDS_Women_Who_Code_Deep_Learning_%22Hello_World%22.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qgenQJaLDYmP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Demystifying Deep Learning Tutorial\n",
        "## WiMLDS x Women Who Code \n",
        "## July 25, 2018\n",
        "### Lisa Nash & Jane Zanzig \n"
      ]
    },
    {
      "metadata": {
        "id": "naD40GxyNokH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The purpose tutorial is to give a \"hello world\" example of building a neural network. We made the tutorial using Colaboratory (which allows us to basically do Google Drive for Jupyter notebooks), but all of the code can be run in Python on your own machine."
      ]
    },
    {
      "metadata": {
        "id": "efl3_dH_2YS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYGB5Q7fDViR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import packages. \n",
        "\n",
        "`keras` is a deep learning library in Python that has a lot of pre-loaded models, so it allows for easy and fast prototyping of neural nets. It supports both *convolutional networks*, which are good at identifying _shapes_ and are more commonly used for images, and *recurrent networks*, which are good at identifying _sequences_ and more commonly used for speech and audio, as well as combinations of the two.\n",
        "\n",
        "`numpy` is a scientific computing package that allows us to do mathematical computations efficiently. For example, you can use `numpy` to multiply matrices or generate (pseudo-)random numbers. \n"
      ]
    },
    {
      "metadata": {
        "id": "XvL7KqiN2bY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Import all the model layers we want to use from keras\n",
        "# If you want to extend the model, you may need to add more here\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UMQ_xqrl6o1i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load data.\n",
        "Here we get a toy dataset example, the MNIST dataset of handwritten digits. This is because a common application of image recognition would be taking a picture of something handwritten and seeing if you can deduce what letter or number it is. There are some variations in the way that people write characters, but they all follow some common patterns. \n",
        "\n",
        "`keras`  comes with data already loaded into training and test sets. If you wanted to replace this with your own data, you'd just need an `X_train`, `y_train`, an `X_test`, and a `y_test`, where `X` contains your features (in this case, images) and `y` contains your labels."
      ]
    },
    {
      "metadata": {
        "id": "ms-Sg1s12uen",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " # Load pre-shuffled MNIST data into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNn9wixU9J3m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " In this case, `X` is images of grayscale handwritten characters. Each image is 28 x 28 pixels, so the input data is a 28 x 28 matrix where the value in each cell is the darkness of that pixel (from 0 to 255)."
      ]
    },
    {
      "metadata": {
        "id": "AddHrZjN24bG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (X_train.shape)\n",
        "# (60000, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4_0ALE2HRqP_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have 60,000 labeled digits in our training set. We can take a look at them. This is a good step to take as a \"sanity check.\" "
      ]
    },
    {
      "metadata": {
        "id": "nMWBjoAjJBdA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Look at data."
      ]
    },
    {
      "metadata": {
        "id": "Q_54eQl326fD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(X_train[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ygzBDUXcmK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reshape data.\n",
        "\n",
        "We need to quickly reshape our data to add a dimension for the depth of the input image. In other words, we want to transform our dataset from having shape (`n, width, height`) to (`n, depth, width, height`). Our MNIST images only have a depth of 1 (darkness); if we had color images, for instance, our depth might be 3, one for each dimension of the RGB scale."
      ]
    },
    {
      "metadata": {
        "id": "w46e7Iew2-cR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0M2OtkQq3Ef5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vtnb3qJSI0Q7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All good! "
      ]
    },
    {
      "metadata": {
        "id": "UTThJkeu3Gpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ir8q02Q-rxO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is just putting our inputs in the right format. We need to cast them as floats, or decimals (because multiplying integers and decimal numbers sometimes gives you weird results). Then we divide them by 255 to make them normalized between 0 and 1. This is something you'll sometimes do when modeling or computing features, although many Python libraries (or any kind of modeling software) will automatically do this for you. "
      ]
    },
    {
      "metadata": {
        "id": "65Bc7gfi3I48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzF6K1kk_zAE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have 60,000 images in our training set, and each one is labeled (a digit between 0 and 9). Currently the shape of the data is a 60,000-long vector stating all of the labels. Instead, we want to have a matrix that has 10 entries, with a 1 in the position of the label, because math. You might have heard this called *one-hot encoding*. \n"
      ]
    },
    {
      "metadata": {
        "id": "WlQ6H_At3LXH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "451pA1it3Or4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XhBP8lGextEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a model! "
      ]
    },
    {
      "metadata": {
        "id": "jr0Cgj4n3RPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model  = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bgm8oYNqAdcj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `Sequential` model is a pre-packaged `keras` model, and comprises a linear stack of layers. If you want to get fancier, you can use the [keras Model API](https://keras.io/models/model/), but that's beyond the scope of this tutorial!\n",
        "\n",
        "Note that we create the model object without referencing our data at all at this point."
      ]
    },
    {
      "metadata": {
        "id": "xM5U3CCY3S8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=32, \n",
        "                 kernel_size=1, \n",
        "                 activation='relu', \n",
        "                 input_shape=(1,28,28)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIdlf8w5zTK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since this is the first layer in the model, we provide an `input_shape` argument. We don't need to do this for the following layers, as subsequent layers will infer the input shape from the output of the previous layer. (Here you could also put `None` to indicate that the length could vary.)\n",
        "\n",
        "`Conv2D` is a 2-dimensional convolutional layer. Convolution just means that it is trying to smooth out the input data (i.e. reduce the noise) without oversimplifying and losing too much of the signal. It can be used for edge detection, smoothing etc. it's just applying a function to all of the values. It also makes sense when you're trying to model things that happen in time. The function here is `relu`, which is short for rectified linear units. \n",
        "\n",
        "This layer creates a 2-dimensional convolution kernel. Here, the arguments we're using are `filters`,  the dimension of the output space, and `kernel_size`, which is the length of the convolution window. The `activation` parameter specifies the activation function, which maps the output to [0,1] space."
      ]
    },
    {
      "metadata": {
        "id": "4anIbWutBWtD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGthaz76FAfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=32, \n",
        "                 kernel_size=1, \n",
        "                 activation='relu'))\n",
        "print(model.output_shape)\n",
        "model.add(MaxPooling2D(pool_size=1,\n",
        "                      strides=1))\n",
        "print(model.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QEjiYdSf7rzb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we've added a few different kinds of layers: another 2D convolution layer, plus a `MaxPooling2D` layer and a `Dropout` layer. Pooling is a way of reducing the dimension by taking the maximum of a moving window. `strides` is a way of specifying the step size, or the overlap (or space between) each window (what happens if `strides` is less than `pool_size`? Greater?).\n",
        "\n",
        "As with any feature engineering problem, coming to the right values for these parameters will be a combination of common sense, understanding your problem, and trial and error. In general, though, you'll probably have higher values for them in earlier layers because the dimensions will be higher, so it makes sense to have higher values, both in terms of computation and common sense."
      ]
    },
    {
      "metadata": {
        "id": "2_hA7w4I3W0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dropout(0.25))\n",
        "print(model.output_shape)\n",
        "model.add(Flatten())\n",
        "print(model.output_shape)\n",
        "model.add(Dense(128, activation='relu')) # this will have an output size of 128\n",
        "print(model.output_shape)\n",
        "model.add(Dropout(0.5))\n",
        "print(model.output_shape)\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "print(model.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsEI11Z_2o7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we keep on adding layers. The `Dropout` layers will randomly set a certain proporiton of the inputs to 0, which helps prevent overfitting. The `Dense` layers will keep all of the inputs. A dropout layer doesn't have any trainable parameters. A dense layer will have weights that it applies to the inputs. \n",
        "\n",
        "Notice that the output of the last layer is 10, because there are 10 labels. The `softmax` activation function will take the vector of 10 values and make them all between 0 and 1 and add up to 1. "
      ]
    },
    {
      "metadata": {
        "id": "jo6spN1xLr1r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configure the learning process\n",
        "To actually configure our model, we need all of the layers we've added to `model` so far, plus the following:\n",
        "- *An optimizer.* This could be the string identifier of an existing optimizer (e.g. as “`rmsprop`” or “`adagrad`”) or a call to an optimizer function (e.g. `optimizer_sgd()``).\n",
        "- *A loss function.* This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (e.g. “`categorical_crossentropy`” or “`mse`”) or a call to a loss function (e.g. `loss_mean_squared_error()``).\n",
        "- *A list of metrics.* A metric could be the string identifier of an existing metric (e.g. `accuracy`) or a call to metric function, possibly one that you defined (e.g. `metric_binary_crossentropy()``)."
      ]
    },
    {
      "metadata": {
        "id": "erK3ca2sFJ5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wZ0RHMCZB3Jz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here you specify what your loss function is to decide how \"good\" your model is. In this case, you need an optimizer as well. You can compare this to the case of a linear regression, where you have a closed-form solution for what the optimal coefficients should be, expressed as a function of the observed data. Here, you _don't_ have that luxury, and are searching over a v non-linear space, and in fact don't know if you're moving in the right direction. Here we chose [adam](https://arxiv.org/abs/1412.6980v8), which we won't go into, but you can read the paper if you like. _Note: Sometimes optimizers also have parameters that you need to tune._\n"
      ]
    },
    {
      "metadata": {
        "id": "q397-7GHFVJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train,  \n",
        "          batch_size=32,\n",
        "          epochs=10, \n",
        "          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQeKQT_rCaYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we fit the model to the data (note this is the first time we reference `X` or `Y` at all). The parameters that we're using here are:\n",
        "- `epochs`, where one epoch = one forward pass and one backward pass of all the training examples\n",
        "- `batch_size`, the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
        "- `verbose` just means that it displays the progress bar. This doesn't affect the model, just what you see and how you interact with it.\n",
        "\n",
        "You can see that the accuracy is increasing over time, but that the gains decrease over time, so a common \"stopping condition\" would be when the difference between the loss function in two consecutive epochs is sufficiently small.\n",
        "\n",
        "It will print out the `loss`, or cost function, for each epoch. Ideally this is decreasing with each run, but you'll notice that the returns are diminishing. Here it also prints out the `accuracy` for each epoch, because we included that in the call to `model.compile()`."
      ]
    },
    {
      "metadata": {
        "id": "lrZAFgNkFYkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M5IH34yiDqlJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we evaluate our model on unseen data, or a test set, to see how well it will generalize (remember overfitting?). The `evaluate()` method applies the model to `X_test` and then compares the results to the true labels, `y_test`, and calculates the loss as well as any of the metrics passed to the initial `model` call (in this case, `accuracy`). \n",
        "\n",
        "If you just want the raw predictions, to do your own scoring or to investigate the results that you're getting in more depth, you can call `model.predict()`."
      ]
    },
    {
      "metadata": {
        "id": "WySXGXvHFk8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOSu34loE2kB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `predict` method gives you predictions for all of the classes based on the input features. Since this is a multi-class prediction problem, you could also choose to do something different with this information. \n",
        "\n",
        "Now we can look at how accurate our predictions were."
      ]
    },
    {
      "metadata": {
        "id": "WpCn0dVUE3Fj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred[6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7DczAYfGeZt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_test[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w6y7tp25_-vt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Things to Try!\n",
        "- Go back through and try different numbers of layers, different types of layers, different hyperparameters. What effect does it have on your results?\n",
        "- Try this same exercise with another dataset! `keras` has [a few other pre-loaded datasets](https://keras.io/datasets/) for you to play with, or find something else you're interested in! "
      ]
    },
    {
      "metadata": {
        "id": "zcjGkRCEFrdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Acknowledgements & Resources\n",
        "\n",
        "We used the tutorial at [Elite Data Science](https://elitedatascience.com/keras-tutorial-deep-learning-in-python) as a starting point for this tutorial. \n",
        "\n",
        "If you're interested in going deeper into neural networks, check out [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)\n",
        "\n",
        "Thanks to our colleague Nat Steinsultz for alerting us to the presence of Colaboratory and the amazing Neocognitron video.\n"
      ]
    },
    {
      "metadata": {
        "id": "VIomHLDvHsmy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}